apiVersion: "kubeflow.org/v1"
kind: "PyTorchJob"
metadata:
  name: {{ .Values.pytorchJob.name }}
  namespace: {{ .Values.pytorchJob.namespace }}
spec:
  pytorchReplicaSpecs:
    Worker:
      replicas: {{ .Values.pytorchJob.workerReplicas }}
      template:
        metadata:
{{- if .Values.scheduler.enabled }}
          labels:
            runai/queue: "{{ .Values.scheduler.queue }}"
{{- end }}
        spec:
{{- if .Values.scheduler.enabled }}
          schedulerName: "{{ .Values.scheduler.name }}"
{{- end }}
          initContainers:
            - name: data-prep
              image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
              imagePullPolicy: {{ .Values.image.pullPolicy }}
              command: ["/bin/sh", "-c"]
              args:
              - |
{{- if .Values.dataPrep.enabled }}
                {{- $dataset := .Values.dataPrep.dataset }}
                {{- $config := index .Values.dataPrep.datasetConfig $dataset }}
                echo "Checking dataset: {{ $dataset }}"
                {{- $missing := false }}
                {{- range $config.outputFiles }}
                if [ ! -f {{ . }} ]; then
                  echo "Missing file: {{ . }}"
                  {{- $missing = true }}
                fi
                {{- end }}

                if [ "{{ $missing }}" = "true" ] || [ "{{ .Values.dataPrep.forcePrepare }}" = "true" ]; then
                  cp -r /app/data_ori/{{ $dataset }} /app/data/{{ $dataset }}
                  echo "Preparing dataset: {{ $dataset }}"
                  python {{ $config.prepareScript }}
                  echo "Data preparation completed for {{ $dataset }}"
                else
                  echo "Dataset {{ $dataset }} already exists"
                fi
{{- end }}
              volumeMounts:
                - name: data-volume
                  mountPath: /app/data
          containers:
            - name: pytorch
              image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
              imagePullPolicy: {{ .Values.image.pullPolicy }}
              command:
                {{- toYaml .Values.pytorchJob.config.command | nindent 16 }}
              args:
                {{- toYaml .Values.pytorchJob.config.args | nindent 16 }}
              env:
                {{- toYaml .Values.pytorchJob.config.env | nindent 16 }}
              resources:
                limits:
                  nvidia.com/gpu: {{ .Values.pytorchJob.gpusPerWorker }}
                requests:
                  cpu: {{ .Values.pytorchJob.resources.requests.cpu }}
                  memory: {{ .Values.pytorchJob.resources.requests.memory }}
              volumeMounts:
                - name: data-volume
                  mountPath: {{ .Values.persistence.mountPath }}
          volumes:
            - name: data-volume
              persistentVolumeClaim:
                claimName: {{ .Values.pytorchJob.name }}-pvc
